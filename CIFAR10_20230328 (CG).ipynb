{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ecb5f2d",
   "metadata": {},
   "source": [
    "## [說明] 由於 CIFAR10 是一個彩色圖像數據集，因此我們不能將其轉換為灰階圖像。我們需要使用原始的彩色圖像進行訓練。以下是使用 Keras 庫訓練 CIFAR10 模型的範例程式碼\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0addee",
   "metadata": {},
   "source": [
    "## 步驟一:載入 CIFAR10資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128dc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db960dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Secure Socket Layer (SSL) certificate solution to solve the CERTIFICATE_VERIFY_FAILED error downloading CIFAR-10.\n",
    "#必須要 import ssl 及如下指定才能載入資料集, 否則會 download 失敗,來源: https://stackoverflow.com/questions/69687794/unable-to-manually-load-cifar10-dataset\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 載入資料集\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "#ChatGPT 提供:\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653256f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將像素值標準化為 0 到 1 之間的浮點數\n",
    "x_train_color = x_train.astype('float32') / 255.0\n",
    "x_test_color = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c9ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 CNN 模型架構\n",
    "model_color = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f0f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model_color.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e82d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 42s 26ms/step - loss: 1.9846 - accuracy: 0.3316 - val_loss: 1.5556 - val_accuracy: 0.4287\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.4123 - accuracy: 0.4919 - val_loss: 1.3238 - val_accuracy: 0.5198\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 1.2658 - accuracy: 0.5470 - val_loss: 1.2237 - val_accuracy: 0.5601\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 1.1668 - accuracy: 0.5856 - val_loss: 1.1605 - val_accuracy: 0.5895\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0831 - accuracy: 0.6163 - val_loss: 1.0875 - val_accuracy: 0.6295\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.0168 - accuracy: 0.6422 - val_loss: 1.1252 - val_accuracy: 0.6159\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.9608 - accuracy: 0.6640 - val_loss: 1.0639 - val_accuracy: 0.6402\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.9084 - accuracy: 0.6836 - val_loss: 1.0431 - val_accuracy: 0.6496\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.8695 - accuracy: 0.6958 - val_loss: 1.0522 - val_accuracy: 0.6409\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.8299 - accuracy: 0.7110 - val_loss: 1.0439 - val_accuracy: 0.6521\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "history_color = model_color.fit(x_train, y_train, epochs=10, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322cccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 1.0439 - accuracy: 0.6521 - 2s/epoch - 7ms/step\n",
      "Color image model accuracy: 0.6521000266075134\n"
     ]
    }
   ],
   "source": [
    "# 彩色圖像模型的準確度\n",
    "test_loss_color, test_acc_color = model_color.evaluate(x_test, y_test, verbose=2)\n",
    "print('Color image model accuracy:', test_acc_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69abe3b",
   "metadata": {},
   "source": [
    "### 在這個範例中，我們從 CIFAR10 數據集中載入彩色圖像和標籤。接著，我們對圖像進行預處理，將像素值標準化為 0 到 1 之間的浮點數。然後，我們建立了一個 CNN 模型架構，用於對彩色圖像進行訓練和預測。最後，我們對模型進行編譯、訓練和測試，並計算了彩色圖像模型的準確度。由於 CIFAR10 數據集的圖像比 MNIST 數據集的圖像更複雜，因此模型的準確度可能會降低。但是，使用彩色圖像作為輸入可能會提高模型的準確度，因為彩色圖像可以提供更多的色彩維度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e530d",
   "metadata": {},
   "source": [
    "## 下面是使用相同 CNN 模型架構來訓練灰階 CIFAR10 模型的範例程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377222d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec504d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 CIFAR10 數據集\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 載入資料集\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "#ChatGPT 提供:\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8adf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將彩色圖像轉換為灰階圖像 (多一個步驟)\n",
    "x_train_gray = np.dot(x_train[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "x_test_gray = np.dot(x_test[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463cf12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將像素值標準化為 0 到 1 之間的浮點數\n",
    "x_train_gray = x_train_gray.astype('float32') / 255.0\n",
    "x_test_gray = x_test_gray.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98bcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將灰階圖像轉換為 32x32x1 的形狀 (多一個步驟)\n",
    "x_train_gray = np.expand_dims(x_train_gray, axis=-1)\n",
    "x_test_gray = np.expand_dims(x_test_gray, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19a2674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 CNN 模型架構\n",
    "model_gray = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45c05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model_gray.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2a59eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 39s 24ms/step - loss: 1.6848 - accuracy: 0.3906 - val_loss: 1.4384 - val_accuracy: 0.4881\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.3230 - accuracy: 0.5378 - val_loss: 1.2188 - val_accuracy: 0.5730\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.1601 - accuracy: 0.5968 - val_loss: 1.1270 - val_accuracy: 0.6058\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0650 - accuracy: 0.6324 - val_loss: 1.0613 - val_accuracy: 0.6310\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9925 - accuracy: 0.6581 - val_loss: 1.0105 - val_accuracy: 0.6493\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9361 - accuracy: 0.6756 - val_loss: 0.9874 - val_accuracy: 0.6627\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8872 - accuracy: 0.6941 - val_loss: 0.9631 - val_accuracy: 0.6719\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.8489 - accuracy: 0.7059 - val_loss: 1.0212 - val_accuracy: 0.6553\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.8113 - accuracy: 0.7218 - val_loss: 0.9493 - val_accuracy: 0.6731\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.7808 - accuracy: 0.7280 - val_loss: 0.9253 - val_accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "history_gray = model_gray.fit(x_train_gray, y_train, epochs=10, \n",
    "                    validation_data=(x_test_gray, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f71c6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.9253 - accuracy: 0.6898 - 2s/epoch - 6ms/step\n",
      "Gray image model accuracy: 0.6898000240325928\n"
     ]
    }
   ],
   "source": [
    "# 灰階圖像模型的準確度\n",
    "test_loss_gray, test_acc_gray = model_gray.evaluate(x_test_gray, y_test, verbose=2)\n",
    "print('Gray image model accuracy:', test_acc_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08c476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
